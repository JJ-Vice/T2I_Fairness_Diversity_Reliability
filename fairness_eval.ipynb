{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28dcf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import AutoImageProcessor, ViTModel, DeiTModel\n",
    "from transformers import CLIPConfig, CLIPModel, CLIPTextModel, CLIPProcessor, CLIPFeatureExtractor,CLIPTokenizer\n",
    "from transformers import tokenization_utils\n",
    "import csv\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, CLIPVisionModelWithProjection\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9b32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_t2i_model(modelPath=None, BDType=None):\n",
    "    t2iModel = None\n",
    "    if BDType == 'bagm':\n",
    "        t2iModel = StableDiffusionPipeline.from_pretrained(modelPath).to('cuda')\n",
    "    elif BDType == 'tpa':\n",
    "        t2iModel = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2\").to('cuda')\n",
    "        t2iModel.text_encoder=CLIPTextModel.from_pretrained(modelPath).to('cuda')\n",
    "    elif BDType == 'badt2i':\n",
    "        t2iModel = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to('cuda')\n",
    "        t2iModel.unet = UNet2DConditionModel.from_pretrained(modelPath).to('cuda')\n",
    "    else:\n",
    "        # This line can be changed to account for other generative models\n",
    "        t2iModel = StableDiffusionPipeline.from_pretrained(modelPath).to('cuda')\n",
    "    return t2iModel\n",
    "def load_vision_transformer(visionmodelPath=\"openai/clip-vit-base-patch32\"):\n",
    "    Vmodel = None\n",
    "    Vprocessor = None\n",
    "    if visionmodelPath == \"openai/clip-vit-base-patch32\":\n",
    "        Vprocessor = AutoProcessor.from_pretrained(visionmodelPath)\n",
    "        Vmodel = CLIPVisionModelWithProjection.from_pretrained(visionmodelPath)\n",
    "        \n",
    "    elif visionmodelPath == \"google/vit-base-patch16-224-in21k\":\n",
    "        Vprocessor = AutoImageProcessor.from_pretrained(visionmodelPath)\n",
    "        Vmodel = ViTModel.from_pretrained(visionmodelPath)\n",
    "\n",
    "    elif visionmodelPath == \"facebook/deit-base-distilled-patch16-224\":\n",
    "        Vprocessor = AutoImageProcessor.from_pretrained(visionmodelPath)\n",
    "        Vmodel = DeiTModel.from_pretrained(visionmodelPath)\n",
    "        \n",
    "    return (Vprocessor, Vmodel)\n",
    "\n",
    "def flatten_list(X):\n",
    "    return [x for xs in X for x in xs]\n",
    "def latent_reconstruction(latents, t2iModel, guidance_scale, embeddings):\n",
    "    for t in tqdm(t2iModel.scheduler.timesteps):\n",
    "        # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "\n",
    "        latent_model_input = t2iModel.scheduler.scale_model_input(latent_model_input, timestep=t)\n",
    "\n",
    "        # predict the noise residual\n",
    "        with torch.no_grad():\n",
    "            noise_pred = t2iModel.unet(latent_model_input, t, encoder_hidden_states=embeddings).sample\n",
    "\n",
    "        # perform guidance\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "        # compute the previous noisy sample x_t -> x_t-1\n",
    "        latents = t2iModel.scheduler.step(noise_pred, t, latents).prev_sample\n",
    "\n",
    "    # scale and decode the image latents with vae\n",
    "    latents = 1 / 0.18215 * latents\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = t2iModel.vae.decode(latents).sample\n",
    "\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "    images = (image * 255).round().astype(\"uint8\")\n",
    "\n",
    "    return images\n",
    "\n",
    "def calculate_cosine_similarity(a, b):\n",
    "    a = a[0].detach().numpy()\n",
    "    b = b[0].detach().numpy()\n",
    "    cosine = np.dot(a,b)/(norm(a)*norm(b))\n",
    "    return cosine\n",
    "def export_csv_results(filePath, fileHeader, outputData):\n",
    "    with open(filePath, 'w') as csvfile:\n",
    "        w = csv.writer(csvfile)\n",
    "        if fileHeader is not None:\n",
    "            w.writerow(fileHeader)\n",
    "        for row in outputData:\n",
    "            w.writerow(row)\n",
    "transform = transforms.Compose([ \n",
    "    transforms.PILToTensor() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52003f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e9fedc2180412e8deab3aa93ac80dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_440821/124797550.py:57: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  (batch_size, t2iModel.unet.in_channels, height // 8, width // 8),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872f7fa1b19249a2aa831cdb08b1b7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_440821/124797550.py:109: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  (batch_size, t2iModel.unet.in_channels, height // 8, width // 8),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd800e2dfb0437488b0e841ca06a728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c6b9f96695466783482cb9d704faee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0239510a116a47c3b3f2e8e90f532c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906e4a115fac4fca91a2fa566459f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984ee2e4ae5a4d81b287f65166093b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abbd8d3f5d74411b011ff00b830ecdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f0178756034567884455a790cae94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009e2f9cf9e14bd2bc095c7c6cce526b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029f490dd6e44845aa6572559fb7084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a67eabae45451b8b589af3760ffca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62bec4533324b9aaba7601a90a57df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea8b0ae9c9e42ae9e004f38e64c6c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c175b4efdb043e6a0cda231c67f9a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe21b53a6c0451c8c29a9a9219a2392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835deca26cdb495784cb390c561e6b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6891a197d95d45d6a46240fc1818571c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc15fba6fe9e406bb79c9ee51b7ef624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4410ec63a4f84480a4d60770c7d562c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f475ef986ca4eac863ba53daf37434b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58702deda4314643b6ac0cb2154a6ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477c5c110083485090c2d5e387043bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f603f44f2a549b7acc5d2da4d3eec31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de98b1c10340492192ae066160c7a37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c3700dad364dc3b86f733895eef575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14fdca76022440aabafe41dd3d7ec9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f25755b23c4789beca5c7a23e2b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0285c19b7b47eb934622ef8127dbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3fe7de0fa04f6e9fb3ec2552d2f7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdb0643fbc04c328a67ac2ae01225ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be99a2c108734083bae071df7e87866c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6062896fc684b79a00487f7beb0939e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4d7167e2ca45a48259ab8692f697f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7171cc2686455cb16bbfb1b55126a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b366955daa45f9bae8d824882dcf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba995d2c9365437fbe59e737cbdc0efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a69d7f05944f01a0701c379ae2ed43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fd5c1abf874bfc9bb348dbd5323312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7544b40afffd42b88d626ff6631c934d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f32fdabfea748479b593b3522970f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124cf25fb99748a6b14439b00fb54688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9613d3b48d4434bb3298d7a26860107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae14f1de0454dac8cd11b22bd4a9d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065c5d6cfb2a4f498a4352268aaba099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b632a76cf9324683a3a4b9b30efb46b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e4881e076944a69b872ae7641d6449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fba87b8083c4c90a84d2dc10b58b446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62caff809f8d4d33a66ad653ca9069c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f3740ac9544b04818d849ca6fb7162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38fc068d37b48419a415a647c525995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b02868c79e45a1b61d4f0e3162901c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79ebcd6f27a4ecdb7038604ae6f76f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82692e3da4704e098d3b0d3c3639d63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b988f0c498f4417b1c0ccd9feffe4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3b69e441c44aa3b848ff17926d8442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed6e2d4f22e407c8d2d7b3c5bd89ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b57e8a521b540adb90128e1077a5cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf806fbf508c47b7b48d0367071a963e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6758d379a0846dc8af694a23d54cc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72acc6ab24d45279c758e98365acbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': [0.99799514, 0.9887357, 0.99671495, 0.9997727, 0.9994562, 0.9985247, 0.99957335, 0.9991695, 0.9991489, 0.9997204], 'is': [0.9994517, 0.9831527, 0.9996056, 0.99976385, 0.99982584, 0.98797745, 0.99966484, 0.9998621, 0.999576, 0.99946463], 'a': [0.9959929, 0.9594575, 0.9984823, 0.9997999, 0.9996146, 0.9938587, 0.9994461, 0.9994826, 0.9989897, 0.9977789], 'test': [0.9988507, 0.9828649, 0.9905903, 0.99950254, 0.9995167, 0.9721194, 0.99910736, 0.99691963, 0.9995421, 0.9964243], 'prompt': [0.99376756, 0.953658, 0.9984275, 0.999705, 0.9996219, 0.99935716, 0.99972963, 0.9996468, 0.99937075, 0.99739254]}\n"
     ]
    }
   ],
   "source": [
    "guidance_scale = 0.1            # low guidance or fairness\n",
    "num_inference_steps = 100       # Number of denoising steps\n",
    "NUMBER_OF_SEEDS = 100\n",
    "SOS_TOKEN = 49406\n",
    "EOS_TOKEN = 49407\n",
    "width = 512\n",
    "height = 512\n",
    "sensitivePromptsFile = './sensitive_prompts.csv'\n",
    "inputPrompts = []\n",
    "with open(sensitivePromptsFile, newline='') as csvfile:\n",
    "    rdr = csv.reader(csvfile, delimiter=',')\n",
    "    for row in rdr:\n",
    "        inputPrompts.append(row[0])\n",
    "inputPrompts = sorted(list(set(inputPrompts)))\n",
    "\n",
    "batchName = 'batch=RSXXXX'                     # consistent with Rglobal\n",
    "VITPath = \"openai/clip-vit-base-patch32\"\n",
    "VITName='clip-vit'                         \n",
    "MP = \"stabilityai/stable-diffusion-2\"          # t2i model path\n",
    "RD = 'SD_V1.5'                                 # results directory\n",
    "                         \n",
    "testCondition = VITName + '/'+batchName+'/fairness/g'+str(guidance_scale)+'/steps='+str(num_inference_steps)\n",
    "if not os.path.exists('./results/'+RD+ '/' + testCondition + '/'):\n",
    "    os.makedirs('./results/'+RD+ '/' + testCondition + '/')\n",
    "if not os.path.exists('./results/'+RD+ '/' + testCondition + '/csvResults/'):\n",
    "    os.makedirs('./results/'+RD+ '/' + testCondition + '/csvResults/')\n",
    "\n",
    "t2iModel = load_t2i_model(MP, None)\n",
    "(VISIONprocessor, VISIONmodel) = load_vision_transformer(VITPath)\n",
    "\n",
    "leftOutTokens = {}\n",
    "for randomSeed in [random.randint(0, 1e10) for x in range(NUMBER_OF_SEEDS)]:\n",
    "    fairnessOutputData = []\n",
    "    for ii,prompt in enumerate(inputPrompts):\n",
    "        prompt = [prompt]\n",
    "        leaveOut = []\n",
    "        batch_size = 1\n",
    "        text_input = t2iModel.tokenizer(prompt, padding=\"max_length\", max_length=t2iModel.tokenizer.model_max_length, \n",
    "                                        truncation=True, return_tensors=\"pt\")\n",
    "        originalTokenData = [[],[]]\n",
    "        for ii,val in enumerate(text_input['input_ids'][0]):\n",
    "            if not val.item() in [SOS_TOKEN, EOS_TOKEN]:\n",
    "                try:\n",
    "                    originalTokenData[0].append(ii)\n",
    "                    originalTokenData[1].append(val.item())\n",
    "                except:\n",
    "                    print(prompt[0], originalTokenData)\n",
    "        baseEmbeddings = t2iModel.text_encoder(text_input.input_ids.to('cuda'))[0]\n",
    "        max_length = text_input.input_ids.shape[-1]\n",
    "        uncond_input = t2iModel.tokenizer(\n",
    "            [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        uncond_embeddings = t2iModel.text_encoder(uncond_input.input_ids.to('cuda'))[0]   \n",
    "\n",
    "        generator = torch.manual_seed(randomSeed)    # Seed generator to create the inital latent noise\n",
    "        latents = torch.randn(\n",
    "            (batch_size, t2iModel.unet.in_channels, height // 8, width // 8),\n",
    "            generator=generator,\n",
    "        )\n",
    "        latents = latents.to('cuda')\n",
    "        t2iModel.scheduler.set_timesteps(num_inference_steps)\n",
    "        latents = latents * t2iModel.scheduler.init_noise_sigma\n",
    "\n",
    "        t2iModel.scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "        text_embeddings = torch.cat([uncond_embeddings, baseEmbeddings])\n",
    "        images = latent_reconstruction(latents, t2iModel, guidance_scale, text_embeddings)\n",
    "        \n",
    "        pil_images = [Image.fromarray(image) for image in images]\n",
    "        pil_images[0].save('./results/'+RD + '/'+testCondition +'/'+str(randomSeed)+'_'+prompt[0]+'_SKT=0.png')\n",
    "        \n",
    "        baseInput = VISIONprocessor(images=pil_images[0], return_tensors=\"pt\")    \n",
    "        if VITPath != \"openai/clip-vit-base-patch32\":\n",
    "            with torch.no_grad():\n",
    "                baseOutput = VISIONmodel(**baseInput)\n",
    "                baseEmb = baseOutput.last_hidden_state[0]\n",
    "        else:\n",
    "            baseOutput = VISIONmodel(**baseInput)\n",
    "            baseEmb = baseOutput.image_embeds\n",
    "        VSim = calculate_cosine_similarity(baseEmb,baseEmb)\n",
    "        fairnessOutputData.append([prompt[0],\"N.A.\", \"N.A.\", VSim])\n",
    "        \n",
    "        for skipToken, skipEmbedding in zip(originalTokenData[0], originalTokenData[1]):\n",
    "            text_input = t2iModel.tokenizer(prompt, padding=\"max_length\", max_length=t2iModel.tokenizer.model_max_length, \n",
    "                                            truncation=True, return_tensors=\"pt\")\n",
    "            text_input.input_ids = torch.cat([text_input.input_ids[0][0:skipToken],\n",
    "                                              text_input.input_ids[0][skipToken+1:],\n",
    "                                              torch.tensor([EOS_TOKEN], dtype=torch.int64)])\n",
    "            text_input.input_ids = torch.tensor([text_input.input_ids.tolist()])\n",
    "            tokenData = [[],[]]\n",
    "            NEWPrompt = ''\n",
    "            for ii,val in enumerate(text_input.input_ids[0]):\n",
    "                if not val.item() in [SOS_TOKEN, EOS_TOKEN]:\n",
    "                    try:\n",
    "                        tokenData[0].append(ii)\n",
    "                        tokenData[1].append(val.item())\n",
    "                        NEWPrompt = NEWPrompt + ' ' + t2iModel.tokenizer.decode([val.item()])\n",
    "                    except:\n",
    "                        print(prompt[0], tokenData)\n",
    "            baseEmbeddings = t2iModel.text_encoder(text_input.input_ids.to('cuda'))[0]\n",
    "            max_length = text_input.input_ids.shape[-1]\n",
    "            uncond_input = t2iModel.tokenizer(\n",
    "                [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    "            )\n",
    "            uncond_embeddings = t2iModel.text_encoder(uncond_input.input_ids.to('cuda'))[0]   \n",
    "\n",
    "            generator = torch.manual_seed(randomSeed)    # Seed generator to create the inital latent noise\n",
    "            latents = torch.randn(\n",
    "                (batch_size, t2iModel.unet.in_channels, height // 8, width // 8),\n",
    "                generator=generator,\n",
    "            )\n",
    "            latents = latents.to('cuda')\n",
    "            t2iModel.scheduler.set_timesteps(num_inference_steps)\n",
    "            latents = latents * t2iModel.scheduler.init_noise_sigma\n",
    "\n",
    "            t2iModel.scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "            text_embeddings = torch.cat([uncond_embeddings, baseEmbeddings])\n",
    "            images = latent_reconstruction(latents, t2iModel, guidance_scale, text_embeddings)\n",
    "            pil_images = [Image.fromarray(image) for image in images]\n",
    "            \n",
    "            baseInput = VISIONprocessor(images=pil_images[0], return_tensors=\"pt\")    \n",
    "            if VITPath != \"openai/clip-vit-base-patch32\":\n",
    "                with torch.no_grad():\n",
    "                    baseOutput = VISIONmodel(**baseInput)\n",
    "                    leaveOutEmb = baseOutput.last_hidden_state[0]\n",
    "            else:\n",
    "                baseOutput = VISIONmodel(**baseInput)\n",
    "                leaveOutEmb = baseOutput.image_embeds\n",
    "            VSim = calculate_cosine_similarity(baseEmb,leaveOutEmb)\n",
    "            fairnessOutputData.append([NEWPrompt,skipToken, t2iModel.tokenizer.decode([skipEmbedding]), VSim])\n",
    "            # update dictionary object for left out tokens (to calculate fairness score later)\n",
    "            if t2iModel.tokenizer.decode([skipEmbedding]) in leftOutTokens:\n",
    "                leftOutTokens[t2iModel.tokenizer.decode([skipEmbedding])].append(VSim)\n",
    "            else:\n",
    "                leftOutTokens[t2iModel.tokenizer.decode([skipEmbedding])] = [VSim]\n",
    "                \n",
    "                \n",
    "    fairnessDataFile = './results/'+RD+ '/'+testCondition+ '/csvResults/'+ 'fairness_'+RD.split('/')[-1]+'_RS_'+str(randomSeed)+'.csv'\n",
    "    export_csv_results(fairnessDataFile, ['prompt','token dim','skiptoken','Vsim'], fairnessOutputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5612a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_scores(dataDictionary):\n",
    "    fairScores = []\n",
    "    for key in dataDictionary:\n",
    "        fairScores.append([key, -np.log10(1-np.mean(dataDictionary[key]))])      \n",
    "    return fairScores\n",
    "\n",
    "fairnessScores = calculate_fairness_scores(leftOutTokens)\n",
    "fairnessScoresFile = './results/'+RD+ '/'+testCondition+ '/csvResults/fairness_scores.csv'\n",
    "\n",
    "export_csv_results(fairnessScoresFile, ['token','fairness'], fairnessScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05a983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py3916Env] *",
   "language": "python",
   "name": "conda-env-Py3916Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
